{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Sorting and Firing Rate Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook provides a comprehensive analysis of spike sorting and firing rate analysis for in vivo electrophysiology data. It uses state-of-the-art libraries such as Neo, SpikeInterface, and Elephant to handle data, perform spike sorting, analyze spike train dynamics, and visualize results.\n",
    "\n",
    "### Objectives\n",
    "- Detect and sort spikes from raw electrophysiological data.\n",
    "- Compute firing rates and analyze spike train dynamics.\n",
    "- Visualize spike train data with raster plots, ISI histograms, and more.\n",
    "\n",
    "### Methods\n",
    "- **Spike Detection**: Threshold-based and template matching approaches.\n",
    "- **Feature Extraction**: Extract key features (e.g., spike width, amplitude).\n",
    "- **Clustering Algorithms**: K-means, Gaussian Mixture Models (GMM), DBSCAN.\n",
    "- **Spike Train Analysis**: Interspike intervals (ISI), peri-stimulus time histograms (PSTH), burst detection.\n",
    "\n",
    "### Tools\n",
    "- **Python Libraries**: Neo, SpikeInterface, Elephant, SciPy, PyWavelets, PySpike.\n",
    "- **Visualization**: Matplotlib, Plotly.\n",
    "\n",
    "### Outcome\n",
    "- Sorted spikes, firing rate histograms, raster plots, and autocorrelograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "Before starting the analysis, we need to install the required libraries if they are not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (use %pip for Jupyter compatibility)\n",
    "%pip install neo spikeinterface elephant quantities matplotlib plotly scikit-learn scipy pywavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import neo  # For data handling\n",
    "import spikeinterface as si  # Core module for SpikeInterface\n",
    "import spikeinterface.extractors as se  # For data loading and extraction\n",
    "import spikeinterface.preprocessing as sp  # For data preprocessing\n",
    "import spikeinterface.sorters as ss  # For spike sorting algorithms\n",
    "import spikeinterface.postprocessing as spost  # For postprocessing sorted data\n",
    "import spikeinterface.qualitymetrics as sq  # For quality control metrics\n",
    "import elephant  # For advanced analysis on spike trains\n",
    "import elephant.statistics as es  # For statistical measures like firing rates\n",
    "import elephant.spike_train_correlation as escorr  # For correlation analysis\n",
    "import elephant.spike_train_generation as estg  # For spike train generation and burst detection\n",
    "import quantities as pq  # For unit handling\n",
    "import matplotlib.pyplot as plt  # For static visualization\n",
    "import plotly.express as px  # For interactive visualization with Plotly\n",
    "from neo.io import NeuralynxIO  # Example IO for Neo data loading\n",
    "import numpy as np  # For numerical operations\n",
    "from scipy.cluster.vq import kmeans  # K-means clustering\n",
    "from sklearn.mixture import GaussianMixture  # GMM clustering\n",
    "from sklearn.cluster import DBSCAN  # DBSCAN clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "This section covers the loading of electrophysiological data using Neo and SpikeInterface, followed by preprocessing steps like bandpass filtering and common reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo\n",
    "from neo.io import NeuralynxIO\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "# Load electrophysiological data using Neo and convert to SpikeInterface format\n",
    "def load_data(file_path):\n",
    "    reader = NeuralynxIO(dirname=file_path)\n",
    "    block = reader.read_block()\n",
    "    segment = block.segments[0]\n",
    "    analog_signal = segment.analogsignals[0]\n",
    "    recording = se.NeoRecordingExtractor(analog_signal)\n",
    "    return recording\n",
    "\n",
    "# Example usage\n",
    "file_path = 'data/sample_data'  # Update with actual path\n",
    "recording = load_data(file_path)\n",
    "print(\"Data Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Preprocessing the data is essential for reducing noise and enhancing signal quality. Apply bandpass filtering and common referencing to the loaded data for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using Neo\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load electrophysiological data using Neo and convert to SpikeInterface format.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the file containing raw data.\n",
    "    \n",
    "    Returns:\n",
    "    - recording (si.BaseRecording): Loaded data in SpikeInterface's RecordingExtractor format.\n",
    "    \"\"\"\n",
    "    reader = NeuralynxIO(dirname=file_path)\n",
    "    block = reader.read_block()\n",
    "    segment = block.segments[0]\n",
    "    analog_signal = segment.analogsignals[0]\n",
    "    recording = se.NeoRecordingExtractor(analog_signal)\n",
    "    return recording\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(recording, freq_min=300, freq_max=3000, common_ref_type='median'):\n",
    "    \"\"\"\n",
    "    Preprocess the loaded data by applying bandpass filtering and common reference.\n",
    "    \n",
    "    Args:\n",
    "    - recording (si.BaseRecording): Loaded data in SpikeInterface's RecordingExtractor format.\n",
    "    - freq_min (int): Minimum frequency for bandpass filter.\n",
    "    - freq_max (int): Maximum frequency for bandpass filter.\n",
    "    - common_ref_type (str): Type of common reference ('median', 'average', etc.).\n",
    "    \n",
    "    Returns:\n",
    "    - recording_preprocessed (si.BaseRecording): Preprocessed data.\n",
    "    \"\"\"\n",
    "    recording_bp = sp.bandpass_filter(recording, freq_min=freq_min, freq_max=freq_max)\n",
    "    recording_cmr = sp.common_reference(recording_bp, reference=common_ref_type)\n",
    "    return recording_cmr\n",
    "\n",
    "# Load and preprocess example data\n",
    "file_path = 'data/sample_data'  # Adjust this to your dataset path\n",
    "recording = load_data(file_path)\n",
    "recording_preprocessed = preprocess_data(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Sorting\n",
    "Perform spike sorting on the preprocessed data using various spike sorting algorithms (e.g., Kilosort2, SpykingCircus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_spikes(recording, sorter_name='kilosort2'):\n",
    "    \"\"\"\n",
    "    Perform spike sorting on the preprocessed data.\n",
    "    \n",
    "    Args:\n",
    "    - recording (si.BaseRecording): Preprocessed recording data.\n",
    "    - sorter_name (str): Name of the sorting algorithm to use (e.g., 'kilosort2').\n",
    "    \n",
    "    Returns:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    \"\"\"\n",
    "    sorter_params = ss.get_default_params(sorter_name)\n",
    "    sorting = ss.run_sorter(sorter_name, recording, output_folder='sorting_output', **sorter_params)\n",
    "    return sorting\n",
    "\n",
    "# Perform spike sorting\n",
    "sorting = sort_spikes(recording_preprocessed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing and Quality Metrics\n",
    "\n",
    "Postprocess sorted spikes to extract waveforms and compute quality metrics such as SNR, ISI violations, and firing rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_sorting(sorting, recording):\n",
    "    \"\"\"\n",
    "    Postprocess the sorted spikes to extract features and waveforms.\n",
    "    \n",
    "    Args:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    - recording (si.BaseRecording): Preprocessed recording data.\n",
    "    \n",
    "    Returns:\n",
    "    - waveform_extractor (si.WaveformExtractor): Extracted waveforms.\n",
    "    \"\"\"\n",
    "    waveform_extractor = spost.WaveformExtractor.create(recording, sorting, folder='waveforms', remove_existing_folder=True)\n",
    "    waveform_extractor.set_params(ms_before=1.5, ms_after=2.5)\n",
    "    waveform_extractor.run()\n",
    "    return waveform_extractor\n",
    "\n",
    "def compute_quality_metrics(waveform_extractor):\n",
    "    \"\"\"\n",
    "    Compute quality metrics for sorted units.\n",
    "    \n",
    "    Args:\n",
    "    - waveform_extractor (si.WaveformExtractor): Extracted waveforms.\n",
    "    \n",
    "    Returns:\n",
    "    - metrics (dict): Quality metrics for each sorted unit.\n",
    "    \"\"\"\n",
    "    metrics = sq.compute_quality_metrics(waveform_extractor, metric_names=['snr', 'isi_violation', 'firing_rate'])\n",
    "    return metrics\n",
    "\n",
    "# Postprocess sorting and compute quality metrics\n",
    "waveform_extractor = postprocess_sorting(sorting, recording_preprocessed)\n",
    "quality_metrics = compute_quality_metrics(waveform_extractor)\n",
    "print(\"Quality Metrics:\", quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Clustering\n",
    "\n",
    "Extract spike waveform features and perform clustering using K-means, GMM, or DBSCAN to group similar spike events into units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(waveform_extractor):\n",
    "    \"\"\"\n",
    "    Extract features from the sorted spike waveforms for clustering.\n",
    "    \n",
    "    Args:\n",
    "    - waveform_extractor (si.WaveformExtractor): Extracted waveforms.\n",
    "    \n",
    "    Returns:\n",
    "    - features (np.ndarray): Feature matrix (e.g., spike width, amplitude, etc.).\n",
    "    \"\"\"\n",
    "    waveforms = waveform_extractor.get_waveforms()\n",
    "    # Example feature extraction: mean and std of spike waveforms\n",
    "    spike_width = np.mean(np.abs(waveforms), axis=(1, 2))\n",
    "    spike_amplitude = np.std(waveforms, axis=(1, 2))\n",
    "    features = np.column_stack((spike_width, spike_amplitude))\n",
    "    return features\n",
    "\n",
    "def cluster_spikes(features, method='kmeans'):\n",
    "    \"\"\"\n",
    "    Cluster spikes using specified clustering algorithm.\n",
    "    \n",
    "    Args:\n",
    "    - features (np.ndarray): Feature matrix for clustering.\n",
    "    - method (str): Clustering method ('kmeans', 'gmm', 'dbscan').\n",
    "    \n",
    "    Returns:\n",
    "    - labels (np.ndarray): Cluster labels for each spike.\n",
    "    \"\"\"\n",
    "    if method == 'kmeans':\n",
    "        centroids, labels = kmeans(features, 3)\n",
    "    elif method == 'gmm':\n",
    "        gmm = GaussianMixture(n_components=3).fit(features)\n",
    "        labels = gmm.predict(features)\n",
    "    elif method == 'dbscan':\n",
    "        db = DBSCAN(eps=0.5, min_samples=5).fit(features)\n",
    "        labels = db.labels_\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported clustering method.\")\n",
    "    return labels\n",
    "\n",
    "# Extract features and perform clustering\n",
    "features = extract_features(waveform_extractor)\n",
    "labels = cluster_spikes(features, method='kmeans')\n",
    "print(\"Cluster Labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Train Analysis\n",
    "Spike train analysis is essential for understanding how neurons encode and process information in vivo. By examining the temporal patterns of spikes recorded from single or limited-channel electrodes, we can gain insights into various aspects of neuronal activity such as firing rates, synchrony, and burst dynamics. This is particularly important in studying sensory processing, motor control, and cognitive functions in behaving animals. Here, we perform spike train analysis to compute firing rates, spike train correlations, interspike intervals (ISI), and burst detection for a comprehensive understanding of neuronal coding and network dynamics.\n",
    "\n",
    "### Firing Rate Analysis\n",
    "Firing rate analysis involves calculating the number of spikes per unit of time for each neuron (unit). This metric provides a fundamental measure of neuronal excitability and is often used to quantify how neurons respond to sensory stimuli, motor tasks, or cognitive processes. For in vivo single/limited channel electrophysiology, firing rates can reveal how individual neurons or populations of neurons are modulated by behavior, environmental changes, or experimental conditions. We compute the mean firing rate over time and can also visualize firing rate changes during specific experimental epochs.\n",
    "\n",
    "### Spike Train Correlations\n",
    "Spike train correlation analysis helps in understanding the temporal coordination and synchrony between different neurons. In the context of in vivo recordings, analyzing the correlations between spike trains of multiple units can provide evidence for shared synaptic inputs, network connectivity, or coordinated activity patterns that are associated with specific behavioral states. By computing pairwise correlations between spike trains, we can infer functional connectivity and identify neurons that may work together to encode sensory inputs or motor outputs.\n",
    "\n",
    "### Interspike Interval (ISI) Analysis\n",
    "Interspike interval (ISI) analysis involves calculating the time intervals between consecutive spikes for each neuron. This analysis provides insights into the regularity and variability of neuronal firing, which can indicate the presence of different firing patterns such as tonic firing, burst firing, or irregular spiking. In the context of in vivo electrophysiology, ISI analysis can reveal the underlying mechanisms of neural coding, such as adaptation, refractory periods, or network oscillations, which are crucial for understanding how the brain processes information in real-time.\n",
    "\n",
    "### Burst Detection\n",
    "Burst detection is the process of identifying clusters of spikes that occur within a short time interval. Bursting activity is often seen in certain types of neurons, and it can play a critical role in synaptic plasticity, signal amplification, and rhythmic brain activities. In in vivo electrophysiology studies, burst detection can provide insights into neuronal communication and synchronization, as well as help identify potential pathological conditions such as epilepsy. Detecting bursts and analyzing their properties, such as duration, frequency, and inter-burst intervals, can help elucidate the temporal organization of neural circuits and their functional states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_firing_rate(sorting, bin_size=100 * pq.ms):\n",
    "    \"\"\"\n",
    "    Calculate the mean firing rate from the sorted spike data.\n",
    "    \n",
    "    Args:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    - bin_size (Quantity): Time bin size for firing rate calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - firing_rates (dict): Dictionary of firing rates for each unit.\n",
    "    \"\"\"\n",
    "    firing_rates = {}\n",
    "    for unit_id in sorting.unit_ids:\n",
    "        spike_train = sorting.get_unit_spike_train(unit_id) * pq.s\n",
    "        rate = es.mean_firing_rate(spike_train, t_start=0 * pq.s, t_stop=max(spike_train), bin_size=bin_size)\n",
    "        firing_rates[unit_id] = rate\n",
    "    return firing_rates\n",
    "\n",
    "# Calculate firing rates\n",
    "firing_rates = calculate_firing_rate(sorting)\n",
    "print(\"Firing Rates (Hz):\", firing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_spike_train_correlation(sorting, method='pearson'):\n",
    "    \"\"\"\n",
    "    Analyze spike train correlations between units using binned spike trains.\n",
    "    \n",
    "    Args:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    - method (str): Correlation method ('pearson', 'spearman', etc.).\n",
    "    \n",
    "    Returns:\n",
    "    - correlation_matrix (np.ndarray): Correlation matrix of spike trains.\n",
    "    \"\"\"\n",
    "    # Convert sorted spikes to binned spike trains for correlation analysis\n",
    "    binned_spiketrains = [es.BinnedSpikeTrain(sorting.get_unit_spike_train(unit_id) * pq.s, binsize=5 * pq.ms) for unit_id in sorting.unit_ids]\n",
    "    correlation_matrix = escorr.corrcoef(binned_spiketrains, method=method)\n",
    "    return correlation_matrix\n",
    "\n",
    "# Perform spike train correlation analysis\n",
    "correlation_matrix = analyze_spike_train_correlation(sorting)\n",
    "print(\"Correlation Matrix:\", correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_isi_histogram(sorting, unit_id):\n",
    "    \"\"\"\n",
    "    Compute the Interspike Interval (ISI) histogram for a given unit.\n",
    "    \n",
    "    Args:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    - unit_id (int): ID of the unit for which to compute ISI.\n",
    "    \n",
    "    Returns:\n",
    "    - isi_hist (np.ndarray): ISI histogram.\n",
    "    - bins (np.ndarray): Bin edges for ISI histogram.\n",
    "    \"\"\"\n",
    "    spike_train = sorting.get_unit_spike_train(unit_id) * pq.s\n",
    "    isi = np.diff(spike_train)\n",
    "    isi_hist, bins = np.histogram(isi, bins=np.arange(0, 1, 0.01))  # ISI in seconds\n",
    "    return isi_hist, bins\n",
    "\n",
    "# Compute and plot ISI histogram for a specific unit\n",
    "isi_hist, bins = compute_isi_histogram(sorting, sorting.unit_ids[0])\n",
    "print(\"ISI Histogram:\", isi_hist)\n",
    "\n",
    "def plot_isi_histogram(isi_hist, bins):\n",
    "    \"\"\"\n",
    "    Plot ISI histogram using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "    - isi_hist (np.ndarray): ISI histogram.\n",
    "    - bins (np.ndarray): Bin edges for ISI histogram.\n",
    "    \"\"\"\n",
    "    plt.bar(bins[:-1], isi_hist, width=np.diff(bins))\n",
    "    plt.xlabel('Interspike Interval (s)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('ISI Histogram')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ISI histogram\n",
    "plot_isi_histogram(isi_hist, bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bursts(spike_train, burst_threshold=3):\n",
    "    \"\"\"\n",
    "    Detect bursts in spike trains based on a threshold ISI value.\n",
    "    \n",
    "    Args:\n",
    "    - spike_train (elephant.SpikeTrain): Spike train data.\n",
    "    - burst_threshold (float): Threshold ISI (in ms) below which spikes are considered to be in a burst.\n",
    "    \n",
    "    Returns:\n",
    "    - bursts (list of lists): Each list contains spike times that form a burst.\n",
    "    \"\"\"\n",
    "    isi = np.diff(spike_train.magnitude)\n",
    "    bursts = []\n",
    "    current_burst = [spike_train[0]]\n",
    "\n",
    "    for i, interval in enumerate(isi):\n",
    "        if interval < burst_threshold:\n",
    "            current_burst.append(spike_train[i + 1])\n",
    "        else:\n",
    "            if len(current_burst) > 1:  # Ensure it's a burst, not a single spike\n",
    "                bursts.append(current_burst)\n",
    "            current_burst = [spike_train[i + 1]]\n",
    "\n",
    "    # Include last burst if any\n",
    "    if len(current_burst) > 1:\n",
    "        bursts.append(current_burst)\n",
    "    \n",
    "    return bursts\n",
    "\n",
    "# Example burst detection on a spike train\n",
    "example_spike_train = es.BinnedSpikeTrain(sorting.get_unit_spike_train(sorting.unit_ids[0]) * pq.s, binsize=5 * pq.ms)\n",
    "bursts = detect_bursts(example_spike_train)\n",
    "print(\"Detected Bursts:\", bursts)\n",
    "\n",
    "def plot_bursts(bursts):\n",
    "    \"\"\"\n",
    "    Plot detected bursts using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "    - bursts (list of lists): Each list contains spike times that form a burst.\n",
    "    \"\"\"\n",
    "    for i, burst in enumerate(bursts):\n",
    "        plt.plot(burst, np.full(len(burst), i), '|', markersize=10)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Burst Number')\n",
    "    plt.title('Detected Bursts')\n",
    "    plt.show()\n",
    "\n",
    "# Plot detected bursts\n",
    "plot_bursts(bursts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Visualize raster plots, firing rate histograms, correlation matrices, and ISI histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # For static visualizations\n",
    "import seaborn as sns  # For enhanced visualization with correlation heatmaps\n",
    "import plotly.express as px  # For interactive visualizations with Plotly\n",
    "import numpy as np  # For numerical operations\n",
    "\n",
    "def plot_firing_rate_histogram(firing_rates):\n",
    "    \"\"\"\n",
    "    Plot histogram of firing rates using Plotly for interactive exploration.\n",
    "    \n",
    "    Args:\n",
    "    - firing_rates (dict): Firing rates of units.\n",
    "    \"\"\"\n",
    "    fig = px.histogram(x=list(firing_rates.values()), labels={'x': 'Firing Rate (Hz)'})\n",
    "    fig.update_layout(title=\"Firing Rate Histogram\", xaxis_title=\"Firing Rate (Hz)\", yaxis_title=\"Count\")\n",
    "    fig.show()\n",
    "\n",
    "def plot_raster(sorting):\n",
    "    \"\"\"\n",
    "    Plot raster plot of the spike sorting results.\n",
    "    \n",
    "    Args:\n",
    "    - sorting (si.BaseSorting): Sorted spike data.\n",
    "    \"\"\"\n",
    "    spike_times = [sorting.get_unit_spike_train(unit_id) for unit_id in sorting.unit_ids]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.eventplot(spike_times, colors='black')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Units')\n",
    "    plt.title('Raster Plot of Spike Trains')\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_matrix(correlation_matrix):\n",
    "    \"\"\"\n",
    "    Plot correlation matrix using Seaborn for enhanced visualization.\n",
    "    \n",
    "    Args:\n",
    "    - correlation_matrix (np.ndarray): Correlation matrix of spike trains.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='viridis', cbar=True)\n",
    "    plt.title('Spike Train Correlation Matrix')\n",
    "    plt.xlabel('Neuron Index')\n",
    "    plt.ylabel('Neuron Index')\n",
    "    plt.show()\n",
    "\n",
    "def plot_isi_histogram(isi_hist, bins):\n",
    "    \"\"\"\n",
    "    Plot ISI histogram using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "    - isi_hist (np.ndarray): ISI histogram.\n",
    "    - bins (np.ndarray): Bin edges for ISI histogram.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(bins[:-1], isi_hist, width=np.diff(bins), color='blue', edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Interspike Interval (s)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Interspike Interval (ISI) Histogram')\n",
    "    plt.show()\n",
    "\n",
    "def plot_burst_detection(bursts, spike_train_duration):\n",
    "    \"\"\"\n",
    "    Plot detected bursts in spike trains.\n",
    "    \n",
    "    Args:\n",
    "    - bursts (dict): Burst times for each unit.\n",
    "    - spike_train_duration (float): Duration of the spike train recording.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for unit_id, burst_times in bursts.items():\n",
    "        plt.vlines(burst_times, unit_id - 0.4, unit_id + 0.4, colors='red')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Units')\n",
    "    plt.title('Burst Detection in Spike Trains')\n",
    "    plt.xlim(0, spike_train_duration)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage assuming data is prepared\n",
    "# Replace 'firing_rates', 'sorting', 'correlation_matrix', 'isi_hist', 'bins', and 'bursts' with actual analysis results.\n",
    "\n",
    "# Example firing rates for visualization\n",
    "firing_rates = {0: 5.2, 1: 3.5, 2: 7.8, 3: 6.1}\n",
    "\n",
    "# Generate synthetic data for demonstration\n",
    "example_sorting = ...  # Replace with actual SpikeInterface sorting object\n",
    "correlation_matrix = np.random.rand(4, 4)  # Replace with actual correlation matrix\n",
    "isi_hist = np.random.poisson(5, 100)  # Replace with actual ISI histogram\n",
    "bins = np.linspace(0, 1, 101)  # Example bin edges for ISI histogram\n",
    "bursts = {0: [0.2, 0.7, 1.3], 1: [0.5, 1.1], 2: [0.8, 1.5]}  # Replace with actual burst detection data\n",
    "spike_train_duration = 2.0  # Example duration in seconds\n",
    "\n",
    "# Plot all visualizations\n",
    "plot_firing_rate_histogram(firing_rates)\n",
    "plot_raster(example_sorting)\n",
    "plot_correlation_matrix(correlation_matrix)\n",
    "plot_isi_histogram(isi_hist, bins)\n",
    "plot_burst_detection(bursts, spike_train_duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we performed spike sorting and firing rate analysis using electrophysiological data. We covered data loading, preprocessing, sorting, feature extraction, clustering, spike train analysis, and visualization techniques."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
